{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf86b3-83fa-4971-8825-dfdb3e51e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exllamav2 import ExLlamaV2, ExLlamaV2Config, ExLlamaV2Cache, ExLlamaV2Tokenizer, Timer\n",
    "from exllamav2.generator import ExLlamaV2DynamicGenerator, ExLlamaV2Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f432b-0d7b-4373-846f-4e6b4d3f4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cache_tokens = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da36e32-91e6-493b-b5cd-75d26ac48fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/cwinkler/m3-llm/models/Qwen3-8B-exl2\"\n",
    "config = ExLlamaV2Config(model_dir)\n",
    "config.arch_compat_overrides()\n",
    "model = ExLlamaV2(config)\n",
    "cache = ExLlamaV2Cache(model, max_seq_len = total_cache_tokens, lazy = True)\n",
    "model.load_autosplit(cache, progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd009b1-b248-45b4-a0f2-85a527547b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ExLlamaV2Tokenizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f7cdf-054d-4b1d-9f04-56b3846417bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|im_start|>system\\nDu bist ein hilfreicher Assistent.<|im_end|>\n",
    "<|im_start|>user\\nErkl√§re den Heise Verlag!<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "\n",
    "</think>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0fca5-5478-45e9-9837-f5fb9d1acec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 2500\n",
    "gen_settings = ExLlamaV2Sampler.Settings.greedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e7c28-ac43-45e2-be98-6fb1f2c8bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ExLlamaV2DynamicGenerator(\n",
    "    model = model,\n",
    "    cache = cache,\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "generator.warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd108be6-00b3-4b38-a596-ef6dd4fd52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as used:\n",
    "    output = generator.generate(\n",
    "        prompt = prompt,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        encode_special_tokens = True,\n",
    "        gen_settings = gen_settings\n",
    "    )\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bc890-b957-4531-981b-28c374e4b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens / used.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e527b14-2dfd-4dbb-92eb-bbae82a22374",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67ca11-2dbe-4ae9-9f15-76a31c41815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
