{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exllamav2 import ExLlamaV2, ExLlamaV2Config, ExLlamaV2Cache, ExLlamaV2Tokenizer\n",
    "from exllamav2.generator import ExLlamaV2StreamingGenerator, ExLlamaV2Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1a3c3-4930-4b94-9642-6b6efd3d5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"/home/cwinkler/oreilly/models/Qwen3-8B-exl2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExLlamaV2Config()\n",
    "config.model_dir = model_directory\n",
    "config.prepare()\n",
    "\n",
    "model = ExLlamaV2(config)\n",
    "print(\"Loading model: \" + model_directory)\n",
    "\n",
    "cache = ExLlamaV2Cache(model, lazy = True)\n",
    "model.load_autosplit(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c74685",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ExLlamaV2Tokenizer(config)\n",
    "\n",
    "# Initialize generator\n",
    "\n",
    "generator = ExLlamaV2StreamingGenerator(model, cache, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ExLlamaV2Sampler.Settings()\n",
    "settings.temperature = 0.1\n",
    "settings.top_k = 50\n",
    "settings.top_p = 0.8\n",
    "settings.token_repetition_penalty = 1.05\n",
    "settings.disallow_tokens(tokenizer, [tokenizer.eos_token_id])\n",
    "\n",
    "max_new_tokens = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|im_start|>system\\nDu bist ein hilfreicher Assistent.<|im_end|>\n",
    "<|im_start|>user\\nErkl√§re den Heise Verlag!<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<think>\n",
    "\n",
    "</think>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(prompt)\n",
    "prompt_tokens = input_ids.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33684d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.set_stop_conditions([])\n",
    "generator.begin_stream(input_ids, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "generated_tokens = 0\n",
    "while True:\n",
    "    chunk, eos, _ = generator.stream()\n",
    "    generated_tokens += 1\n",
    "    print (chunk, end = \"\")\n",
    "    sys.stdout.flush()\n",
    "    if eos or generated_tokens == max_new_tokens: break\n",
    "\n",
    "used = time.time() - start\n",
    "tps = generated_tokens / used\n",
    "print(f\"\\n\\n{used} seconds, {tps} tokens/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca355721",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669131c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
