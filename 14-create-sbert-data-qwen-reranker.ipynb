{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df14dac-622b-476b-980b-b94e26a5aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d043cf-0106-4542-8829-98258360a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(instruction, query, doc):\n",
    "    if instruction is None:\n",
    "        instruction = 'Given a question, retrieve relevant passages that answer the question'\n",
    "    output = \"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\".format(instruction=instruction,query=query, doc=doc)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f661f0-609b-40c9-ae17-6caa6cbcf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs(pairs):\n",
    "    inputs = tokenizer(\n",
    "        pairs, padding=False, truncation='longest_first',\n",
    "        return_attention_mask=False, max_length=max_length - len(prefix_tokens) - len(suffix_tokens)\n",
    "    )\n",
    "    for i, ele in enumerate(inputs['input_ids']):\n",
    "        inputs['input_ids'][i] = prefix_tokens + ele + suffix_tokens\n",
    "    inputs = tokenizer.pad(inputs, padding=True, return_tensors=\"pt\", max_length=max_length)\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(model.device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abbcd8-2451-4e54-bdbf-a144aef6047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_logits(inputs, **kwargs):\n",
    "    batch_scores = model(**inputs).logits[:, -1, :]\n",
    "    true_vector = batch_scores[:, token_true_id]\n",
    "    false_vector = batch_scores[:, token_false_id]\n",
    "    batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "    batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "    scores = batch_scores[:, 1].exp().tolist()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc154a7-e3de-4949-b52f-848923116c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"Qwen/Qwen3-Reranker-4B\"\n",
    "model_name = \"Qwen/Qwen3-Reranker-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "model = model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float16, attn_implementation=\"flash_attention_2\").cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca8641-ccdd-4d9d-9d38-cd820bef368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-score\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48765f1d-4197-4d01-921f-5ac24d0fe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff48f7f-8344-493d-bf3c-89f225305891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993d163-2539-4382-b577-c0503f44e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8f8d9-39bd-44fa-b2c8-964f5cb08e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence1\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e2d9f-db54-4727-9884-ad6fe5de33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence2\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18319417-61be-47c5-85c9-b7e7d8bcba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_false_id = tokenizer.convert_tokens_to_ids(\"no\")\n",
    "token_true_id = tokenizer.convert_tokens_to_ids(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837659f-f3f2-49a0-8b9f-2ae9fb6d7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 8192\n",
    "\n",
    "prefix = \"<|im_start|>system\\nJudge whether the documents are similar . Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "prefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\n",
    "suffix_tokens = tokenizer.encode(suffix, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dc23c-27cd-4b40-af5e-d55917cbd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.concat([df.head(20), df.sample(20, random_state=42)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6374e0-b201-4ab8-96d8-d7f70fa9fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [format_instruction(\"Given two sentences, calculate their similarity\", query, doc) \n",
    "           for query, doc in zip(dft[\"sentence1\"], dft[\"sentence2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977623c-3e5c-42df-86d5-7ad61f593418",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tokenize the input texts\n",
    "max_length = 8192\n",
    "inputs = process_inputs(pairs)\n",
    "scores = compute_logits(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb756f-ba20-4db8-8145-b5ec956a3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"scores\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d65e2-7295-4132-ad28-fa04f64ce5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be97dd6-e184-4b0e-ac4a-038dd86ad931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
